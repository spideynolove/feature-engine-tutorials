{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee5efd0",
   "metadata": {},
   "source": [
    "# Datetime variable transformation\n",
    "\n",
    "The **DatetimeFeatures()** transformer is able to extract many different datetime features from existing datetime variables present in a dataframe. Some of these features are numerical, such as month, year, day of the week, week of the year, etc. and some are binary, such as whether that day was a weekend day or was the last day of its correspondent month. All features are cast to integer before adding them to the dataframe. <br>\n",
    "DatetimeFeatures() converts datetime variables whose dtype is originally object or categorical to a datetime format, but it does not work with variables whose original dtype is numerical. <br>\n",
    "    \n",
    "For this demonstration, we use the Metro Interstate Traffic Volume Data Set, which is publicly available at https://archive.ics.uci.edu/ml/datasets/Metro+Interstate+Traffic+Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23666c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for starters, we import the relevant modules and the DatetimeFeatures class\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from feature_engine.datetime import DatetimeFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd886e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and inspect the dataset\n",
    "data = pd.read_csv('../data/Metro_Interstate_Traffic_Volume.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6049d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b97ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the columns typing and check for potentially missing values\n",
    "pd.DataFrame({\"type\":data.dtypes, \"nan count\":data.isna().sum()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bc761",
   "metadata": {},
   "source": [
    "As it seems, this dataset only contains one datetime variable (named, indeed, _date\\_time_). <br>\n",
    "Let's say we wanted to extract the _day of the month_ and the _hour_ features from it.\n",
    "Since _date\\_time_ happens to be the only datetime variable in this dataset, we can do either of the following\n",
    "- let the transformer search for all datetime variables by initializing it with variables=None (which is the default option anyway)\n",
    "- specify which variables are going to be processed, which in this case would be setting variables=\"date_time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4294f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtfs = DatetimeFeatures(\n",
    "    variables=None,\n",
    "    features_to_extract=[\"day_of_month\", \"hour\"]\n",
    ")\n",
    "\n",
    "# as per scikit-learn and feature-engine convention, we call the fit and transform method\n",
    "# to process the data (even though this particular transformer does not learn any parameters)\n",
    "dtfs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which variables have been picked up as datetime during fit\n",
    "dtfs.variables_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4d7dab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_transf = dtfs.transform(data)\n",
    "data_transf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ad059",
   "metadata": {},
   "source": [
    "Notably, the dataframe identified that the object-like _date\\_time_ variable could be cast to datetime and acquired the two columns _date\\_time\\_dotm_ and _date\\_time\\_hour_ corresponding to the features we required through the _features\\_to\\_extract_ argument. <br>\n",
    "**Note**: the original _date\\_time_ column was removed from the dataframe in the process, as per default behaviour. If we want to keep it, we need to initialize the transformer passing drop_original=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f5d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time we specify what variable(s) we want the features extracted from\n",
    "# we also want to keep the original datetime variable(s).\n",
    "dtfs = DatetimeFeatures(\n",
    "    variables=\"date_time\",\n",
    "    features_to_extract=[\"day_of_month\", \"hour\"],\n",
    "    drop_original=False\n",
    ")\n",
    "\n",
    "data_transf = dtfs.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692e18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9418b5",
   "metadata": {},
   "source": [
    "There are many more datetime features that DatetimeFeatures() can extract; see the docs for a full list. <br>\n",
    "The argument _features\\_to\\_extract_ has a default option aswell. Let's quickly see what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174e1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtfs = DatetimeFeatures(features_to_extract=None)\n",
    "\n",
    "data_transf = dtfs.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only show columns that were extracted from date_time\n",
    "data_transf.filter(regex=\"date_time*\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c90276d",
   "metadata": {},
   "source": [
    "As shown above, DatetimeFeatures() extracts _month_, _year_, _day of the week_, _day of the month_, _hour_, _minute_ and _second_ by default. <br>\n",
    "**Note**: when a variable only contains date information all the time features default to 00:00:00 time; conversely, when a variable only contains time information, date features default to today's date at the time of calling the transform method.\n",
    "\n",
    "If we really want to extract _all_ of the available features we can set _features\\_to\\_extract_ to the special value \"all\". Beware, though, as your feature space might grow significantly and most of the extracted features are most likely not going to be too relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36141dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtfs = DatetimeFeatures(features_to_extract=\"all\")\n",
    "\n",
    "data_transf = dtfs.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388be6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_transf.filter(regex=\"date_time*\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172c0eb",
   "metadata": {},
   "source": [
    "Another thing to keep in mind is that oftentimes most of these features are going to be quasi-constant if not constant altogether. This can be for several reason, most likely due to the particular time window in which the data was collected. <br>\n",
    "We can thus combine the DatetimeFeatures() and DropConstantFeatures() transformers from feature_engine in a scikit-learn pipeline to automatically get rid of features we deem irrelevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9286bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop('holiday', axis=1, inplace = True)\n",
    "data['holiday'] = data['holiday'].replace({pd.NA: None, pd.NaT: None, np.nan: None})\n",
    "data_for_pipe = data.drop('holiday', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7e9d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('datetime_extraction', DatetimeFeatures(features_to_extract=[\"year\", \"day_of_month\", \"minute\", \"second\"])),\n",
    "    ('drop_constants', DropConstantFeatures())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf12c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.isnull().sum()[data.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa189406",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transf = pipe.fit_transform(data_for_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1879dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fbadc",
   "metadata": {},
   "source": [
    "Since all data was gathered with only hour-precision, the _minute_ and _second_ features we had requested were extracted by DatetimeFeatures() but subsequently dropped by DropConstantFeatures(). This way we can avoid our feature space to become overly cluttered with useless information even when we are not being particularly diligent with the features we request to extract."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
