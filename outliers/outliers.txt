Directory structure:
└── outliers/
    ├── ArbitraryOutlierCapper.py
    ├── OutlierTrimmer.py
    └── Winsorizer.py

================================================
File: ArbitraryOutlierCapper.py
================================================
"""
# ArbitraryOutlierCapper
The ArbitraryOutlierCapper() caps the maximum or minimum values of a variable
at an arbitrary value indicated by the user.

The user must provide the maximum or minimum values that will be used <br>
to cap each variable in a dictionary {feature : capping_value}
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from feature_engine.outliers import ArbitraryOutlierCapper


def load_titanic(filepath='../data/titanic.csv'):
    data = pd.read_csv(filepath)
    data = data.replace('?', np.nan)
    data['cabin'] = data['cabin'].astype(str).str[0]
    data['pclass'] = data['pclass'].astype('O')
    data['embarked'].fillna('C', inplace=True)
    data['fare'] = data['fare'].astype('float')
    data['fare'].fillna(data['fare'].median(), inplace=True)
    data['age'] = data['age'].astype('float')
    data['age'].fillna(data['age'].median(), inplace=True)
    data.drop(['name', 'ticket'], axis=1, inplace=True)
    return data


def plot_hist(data, col):
    plt.figure(figsize=(8, 5))
    plt.hist(data[col], bins=30)
    plt.title('Distribution of ' + col)
    return plt.show()


data = load_titanic()
data.sample(5)
X_train, X_test, y_train, y_test = train_test_split(data.drop('survived',
    axis=1), data['survived'], test_size=0.3, random_state=0)
print('train data:', X_train.shape)
print('test data:', X_test.shape)
plot_hist(data, 'age')
plot_hist(data, 'fare')
print('Max age:', data.age.max())
print('Max fare:', data.fare.max())
print('Min age:', data.age.min())
print('Min fare:', data.fare.min())
"""Parameters
----------
max_capping_dict : dictionary, default=None
    Dictionary containing the user specified capping values for the right tail of
    the distribution of each variable (maximum values).

min_capping_dict : dictionary, default=None
    Dictionary containing user specified capping values for the eft tail of the
    distribution of each variable (minimum values).

missing_values : string, default='raise'
    Indicates if missing values should be ignored or raised. If
    `missing_values='raise'` the transformer will return an error if the
    training or the datasets to transform contain missing values.
"""
capper = ArbitraryOutlierCapper(max_capping_dict={'age': 50, 'fare': 150},
    min_capping_dict=None)
capper.fit(X_train)
print('Maximum caps:', capper.right_tail_caps_)
capper.left_tail_caps_
train_t = capper.transform(X_train)
test_t = capper.transform(X_test)
print('Max age after capping:', train_t.age.max())
print('Max fare after capping:', train_t.fare.max())
capper = ArbitraryOutlierCapper(max_capping_dict=None, min_capping_dict={
    'age': 10, 'fare': 100})
capper.fit(X_train)
capper.right_tail_caps_
capper.left_tail_caps_
train_t = capper.transform(X_train)
test_t = capper.transform(X_test)
print('Min age:', train_t.age.min())
print('Min fare:', train_t.fare.min())
capper = ArbitraryOutlierCapper(min_capping_dict={'age': 5, 'fare': 5},
    max_capping_dict={'age': 60, 'fare': 150})
capper.fit(X_train)
capper.right_tail_caps_
capper.left_tail_caps_
train_t = capper.transform(X_train)
test_t = capper.transform(X_test)
print('Max age:', train_t.age.max())
print('Max fare:', train_t.fare.max())
print('Min age:', train_t.age.min())
print('Min fare:', train_t.fare.min())
plot_hist(train_t, 'age')
plot_hist(train_t, 'fare')



================================================
File: OutlierTrimmer.py
================================================
"""
# OutlierTrimmer
The OutlierTrimmer() removes observations with outliers from the dataset.

It works only with numerical variables. A list of variables can be indicated.
Alternatively, the OutlierTrimmer() will select all numerical variables.

The OutlierTrimmer() first calculates the maximum and /or minimum values
beyond which a value will be considered an outlier, and thus removed.

Limits are determined using:

- a Gaussian approximation
- the inter-quantile range proximity rule
- percentiles.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from feature_engine.outliers import OutlierTrimmer


def load_titanic(filepath='../data/titanic.csv'):
    data = pd.read_csv(filepath)
    data = data.replace('?', np.nan)
    data['cabin'] = data['cabin'].astype(str).str[0]
    data['pclass'] = data['pclass'].astype('O')
    data['embarked'].fillna('C', inplace=True)
    data['fare'] = data['fare'].astype('float')
    data['fare'].fillna(data['fare'].median(), inplace=True)
    data['age'] = data['age'].astype('float')
    data['age'].fillna(data['age'].median(), inplace=True)
    data.drop(['name', 'ticket'], axis=1, inplace=True)
    return data


def plot_hist(data, col):
    plt.figure(figsize=(8, 5))
    plt.hist(data[col], bins=30)
    plt.title('Distribution of ' + col)
    return plt.show()


data = load_titanic()
data.sample(5)
X_train, X_test, y_train, y_test = train_test_split(data.drop('survived',
    axis=1), data['survived'], test_size=0.3, random_state=0)
print('train data shape before removing outliers:', X_train.shape)
print('test data shape before removing outliers:', X_test.shape)
print('Max age:', data.age.max())
print('Max fare:', data.fare.max())
print('Min age:', data.age.min())
print('Min fare:', data.fare.min())
plot_hist(data, 'age')
plot_hist(data, 'fare')
"""Parameters
----------

capping_method : str, default=gaussian
    Desired capping method. Can take 'gaussian', 'iqr' or 'quantiles'.
    
tail : str, default=right
    Whether to cap outliers on the right, left or both tails of the distribution.
    Can take 'left', 'right' or 'both'.

fold: int or float, default=3
    How far out to to place the capping values. The number that will multiply
    the std or IQR to calculate the capping values.

variables : list, default=None

missing_values: string, default='raise'
    Indicates if missing values should be ignored or raised."""
trimmer = OutlierTrimmer(capping_method='gaussian', tail='right', fold=3,
    variables=['age', 'fare'])
trimmer.fit(X_train)
trimmer.right_tail_caps_
trimmer.left_tail_caps_
train_t = trimmer.transform(X_train)
test_t = trimmer.transform(X_test)
print('Max age:', train_t.age.max())
print('Max fare:', train_t.fare.max())
print('train data shape after removing outliers:', train_t.shape)
print(f'{X_train.shape[0] - train_t.shape[0]} observations are removed\n')
print('test data shape after removing outliers:', test_t.shape)
print(f'{X_test.shape[0] - test_t.shape[0]} observations are removed')
trimmer = OutlierTrimmer(capping_method='gaussian', tail='both', fold=2,
    variables=['fare', 'age'])
trimmer.fit(X_train)
print('Minimum caps :', trimmer.left_tail_caps_)
print('Maximum caps :', trimmer.right_tail_caps_)
train_t = trimmer.transform(X_train)
test_t = trimmer.transform(X_test)
print('train data shape after removing outliers:', train_t.shape)
print(f'{X_train.shape[0] - train_t.shape[0]} observations are removed\n')
print('test data shape after removing outliers:', test_t.shape)
print(f'{X_test.shape[0] - test_t.shape[0]} observations are removed')
trimmer = OutlierTrimmer(capping_method='iqr', tail='both', variables=[
    'age', 'fare'])
trimmer.fit(X_train)
print('Minimum caps :', trimmer.left_tail_caps_)
print('Maximum caps :', trimmer.right_tail_caps_)
train_t = trimmer.transform(X_train)
test_t = trimmer.transform(X_test)
print('train data shape after removing outliers:', train_t.shape)
print(f'{X_train.shape[0] - train_t.shape[0]} observations are removed\n')
print('test data shape after removing outliers:', test_t.shape)
print(f'{X_test.shape[0] - test_t.shape[0]} observations are removed')
trimmer = OutlierTrimmer(capping_method='quantiles', tail='both', fold=0.02,
    variables=['age', 'fare'])
trimmer.fit(X_train)
print('Minimum caps :', trimmer.left_tail_caps_)
print('Maximum caps :', trimmer.right_tail_caps_)
train_t = trimmer.transform(X_train)
test_t = trimmer.transform(X_test)
print('train data shape after removing outliers:', train_t.shape)
print(f'{X_train.shape[0] - train_t.shape[0]} observations are removed\n')
print('test data shape after removing outliers:', test_t.shape)
print(f'{X_test.shape[0] - test_t.shape[0]} observations are removed')
plot_hist(train_t, 'age')
plot_hist(train_t, 'fare')



================================================
File: Winsorizer.py
================================================
"""
# Winsorizer
Winzorizer finds maximum and minimum values following a Gaussian or skewed distribution as indicated. It can also cap the right, left or both ends of the distribution.

The Winsorizer() caps maximum and / or minimum values of a variable.

The Winsorizer() works only with numerical variables. A list of variables can
be indicated. Alternatively, the Winsorizer() will select all numerical
variables in the train set.

The Winsorizer() first calculates the capping values at the end of the
distribution. The values are determined using:

- a Gaussian approximation,
- the inter-quantile range proximity rule (IQR)
- percentiles.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from feature_engine.outliers import Winsorizer


def load_titanic(filepath='../data/titanic.csv'):
    data = pd.read_csv(filepath)
    data = data.replace('?', np.nan)
    data['cabin'] = data['cabin'].astype(str).str[0]
    data['pclass'] = data['pclass'].astype('O')
    data['embarked'].fillna('C', inplace=True)
    data['fare'] = data['fare'].astype('float')
    data['fare'].fillna(data['fare'].median(), inplace=True)
    data['age'] = data['age'].astype('float')
    data['age'].fillna(data['age'].median(), inplace=True)
    data.drop(['name', 'ticket'], axis=1, inplace=True)
    return data


def plot_hist(data, col):
    plt.figure(figsize=(8, 5))
    plt.hist(data[col], bins=30)
    plt.title('Distribution of ' + col)
    return plt.show()


data = load_titanic()
data.sample(5)
X_train, X_test, y_train, y_test = train_test_split(data.drop('survived',
    axis=1), data['survived'], test_size=0.3, random_state=0)
print('train data:', X_train.shape)
print('test data:', X_test.shape)
print('Max age:', data.age.max())
print('Max fare:', data.fare.max())
plot_hist(data, 'age')
plot_hist(data, 'fare')
"""Parameters
----------
capping_method : str, default=gaussian

    Desired capping method. Can take 'gaussian', 'iqr' or 'quantiles'.

tail : str, default=right

    Whether to cap outliers on the right, left or both tails of the distribution.
    Can take 'left', 'right' or 'both'.

fold: int or float, default=3

    How far out to to place the capping values. The number that will multiply
    the std or IQR to calculate the capping values. Recommended values, 2
    or 3 for the gaussian approximation, or 1.5 or 3 for the IQR proximity
    rule.

variables: list, default=None
  
missing_values: string, default='raise'

    Indicates if missing values should be ignored or raised.
"""
capper = Winsorizer(capping_method='gaussian', tail='right', fold=3,
    variables=['age', 'fare'])
capper.fit(X_train)
capper.right_tail_caps_
capper.left_tail_caps_
plot_hist(capper.transform(X_train), 'age')
train_t = capper.transform(X_train)
test_t = capper.transform(X_test)
train_t.age.max(), train_t.fare.max()
winsor = Winsorizer(capping_method='gaussian', tail='both', fold=2,
    variables='fare')
winsor.fit(X_train)
print('Minimum caps :', winsor.left_tail_caps_)
print('Maximum caps :', winsor.right_tail_caps_)
plot_hist(winsor.transform(X_train), 'fare')
train_t = winsor.transform(X_train)
test_t = winsor.transform(X_test)
print('Max fare:', train_t.fare.max())
print('Min fare:', train_t.fare.min())
winsor = Winsorizer(capping_method='iqr', tail='both', variables=['age',
    'fare'])
winsor.fit(X_train)
winsor.left_tail_caps_
winsor.right_tail_caps_
train_t = winsor.transform(X_train)
test_t = winsor.transform(X_test)
print('Max fare:', train_t.fare.max())
print('Min fare', train_t.fare.min())
winsor = Winsorizer(capping_method='quantiles', tail='both', fold=0.02,
    variables=['age', 'fare'])
winsor.fit(X_train)
print('Minimum caps :', winsor.left_tail_caps_)
print('Maximum caps :', winsor.right_tail_caps_)
train_t = winsor.transform(X_train)
test_t = winsor.transform(X_test)
print('Max age:', train_t.age.max())
print('Min age', train_t.age.min())
plot_hist(train_t, 'age')


